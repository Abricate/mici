<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2.dev0+g1b644f6.d20200630" />
<title>mici.adapters API documentation</title>
<meta name="description" content="Methods for adaptively setting algorithmic parameters of transitions." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding-top:5px;padding-bottom:5px;padding-right:10px;padding-left:35px;text-indent:-25px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:1000px){#sidebar{width:540px;position:fixed;z-index:1;top:0;bottom:0;overflow-x:hidden;overflow-y:auto}#content{margin-left:540px;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}#footer{margin-left:540px}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="mici docs home" href="index.html">
<img width="400" src="../images/mici-logo-rectangular.svg" alt="mici">
</a>
</header>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Package</h3>
<ul>
<li><code><a title="mici" href="index.html">mici</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<code><a title="mici.adapters.Adapter" href="#mici.adapters.Adapter">Adapter</a></code>
<ul class="">
<li><code><a title="mici.adapters.Adapter.initialize" href="#mici.adapters.Adapter.initialize">initialize</a></code></li>
<li><code><a title="mici.adapters.Adapter.update" href="#mici.adapters.Adapter.update">update</a></code></li>
<li><code><a title="mici.adapters.Adapter.finalize" href="#mici.adapters.Adapter.finalize">finalize</a></code></li>
</ul>
</li>
<li>
<code><a title="mici.adapters.DualAveragingStepSizeAdapter" href="#mici.adapters.DualAveragingStepSizeAdapter">DualAveragingStepSizeAdapter</a></code>
<ul class="">
<li><code><a title="mici.adapters.DualAveragingStepSizeAdapter.initialize" href="#mici.adapters.DualAveragingStepSizeAdapter.initialize">initialize</a></code></li>
<li><code><a title="mici.adapters.DualAveragingStepSizeAdapter.update" href="#mici.adapters.DualAveragingStepSizeAdapter.update">update</a></code></li>
<li><code><a title="mici.adapters.DualAveragingStepSizeAdapter.finalize" href="#mici.adapters.DualAveragingStepSizeAdapter.finalize">finalize</a></code></li>
</ul>
</li>
<li>
<code><a title="mici.adapters.OnlineVarianceMetricAdapter" href="#mici.adapters.OnlineVarianceMetricAdapter">OnlineVarianceMetricAdapter</a></code>
<ul class="">
<li><code><a title="mici.adapters.OnlineVarianceMetricAdapter.initialize" href="#mici.adapters.OnlineVarianceMetricAdapter.initialize">initialize</a></code></li>
<li><code><a title="mici.adapters.OnlineVarianceMetricAdapter.update" href="#mici.adapters.OnlineVarianceMetricAdapter.update">update</a></code></li>
<li><code><a title="mici.adapters.OnlineVarianceMetricAdapter.finalize" href="#mici.adapters.OnlineVarianceMetricAdapter.finalize">finalize</a></code></li>
</ul>
</li>
<li>
<code><a title="mici.adapters.OnlineCovarianceMetricAdapter" href="#mici.adapters.OnlineCovarianceMetricAdapter">OnlineCovarianceMetricAdapter</a></code>
<ul class="">
<li><code><a title="mici.adapters.OnlineCovarianceMetricAdapter.initialize" href="#mici.adapters.OnlineCovarianceMetricAdapter.initialize">initialize</a></code></li>
<li><code><a title="mici.adapters.OnlineCovarianceMetricAdapter.update" href="#mici.adapters.OnlineCovarianceMetricAdapter.update">update</a></code></li>
<li><code><a title="mici.adapters.OnlineCovarianceMetricAdapter.finalize" href="#mici.adapters.OnlineCovarianceMetricAdapter.finalize">finalize</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
<article id="content">
<header>
<h1 class="title">Module <code>mici.adapters</code></h1>
</header>
<section id="section-intro">
<p>Methods for adaptively setting algorithmic parameters of transitions.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L0-L458" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Methods for adaptively setting algorithmic parameters of transitions.&#34;&#34;&#34;

from abc import ABC, abstractmethod, abstractproperty
from math import exp, log
import numpy as np
from mici.errors import IntegratorError, AdaptationError
from mici.matrices import (
    PositiveDiagonalMatrix, DensePositiveDefiniteMatrix)


class Adapter(ABC):
    &#34;&#34;&#34;Abstract adapter for implementing schemes to adapt transition parameters.

    Adaptation schemes are assumed to be based on updating a collection of
    adaptation variables (collectively termed the adapter state here) after
    each chain transition based on the sampled chain state and/or statistics of
    the transition such as an acceptance probability statistic. After completing
    a chain of one or more adaptive transitions, the final adapter state may be
    used to perform a final update to the transition parameters.
    &#34;&#34;&#34;

    @abstractmethod
    def initialize(self, chain_state, transition):
        &#34;&#34;&#34;Initialize adapter state prior to starting adaptive transitions.

        Args:
            chain_state (mici.states.ChainState): Initial chain state adaptive
                transition will be started from. May be used to calculate
                initial adapter state but should not be mutated by method.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects may be
                updated in-place by the method.

        Returns:
            adapt_state (Dict[str, Any]): Initial adapter state.
        &#34;&#34;&#34;

    @abstractmethod
    def update(self, adapt_state, chain_state, trans_stats, transition):
        &#34;&#34;&#34;Update adapter state after sampling transition being adapted.

        Args:
            adapt_state (Dict[str, Any]): Current adapter state. Entries will
                be updated in-place by the method.
            chain_state (mici.states.ChainState): Current chain state following
                sampling from transition being adapted. May be used to calculate
                adapter state updates but should not be mutated by method.
            trans_stats (Dict[str, numeric]): Dictionary of statistics
                associated with transition being adapted. May be used to
                calculate adapter state updates but should not be mutated by
                method.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects may be
                updated in-place by the method.
        &#34;&#34;&#34;

    @abstractmethod
    def finalize(self, adapt_state, transition):
        &#34;&#34;&#34;Update transition parameters based on final adapter state or states.

        Optionally, if multiple adapter states are available, e.g. from a set of
        independent adaptive chains, then these adaptation information from all
        the chains may be combined to set the transition parameter(s).

        Args:
            adapt_state (Dict[str, Any] or List[Dict[str, Any]]): Final adapter
                state or a list of adapter states. Arrays / buffers associated
                with the adapter state entries may be recycled to reduce memory
                usage - if so the corresponding entries will be removed from
                the adapter state dictionary / dictionaries.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects will be
                updated in-place by the method.
        &#34;&#34;&#34;


class DualAveragingStepSizeAdapter(Adapter):
    &#34;&#34;&#34;Dual averaging integrator step size adapter.

    Implementation of the dual algorithm step size adaptation algorithm
    described in [1], a modified version of the stochastic optimisation scheme
    of [2]. By default the adaptation is performed to control the `accept_prob`
    statistic of an integration transition to be close to a target value but
    the statistic adapted on can be altered by changing the `adapt_stat_func`.


    References:

      1. Hoffman, M.D. and Gelman, A., 2014. The No-U-turn sampler:
         adaptively setting path lengths in Hamiltonian Monte Carlo.
         Journal of Machine Learning Research, 15(1), pp.1593-1623.
      2. Nesterov, Y., 2009. Primal-dual subgradient methods for convex
         problems. Mathematical programming 120(1), pp.221-259.
    &#34;&#34;&#34;

    def __init__(self, adapt_stat_target=0.8, adapt_stat_func=None,
                 log_step_size_reg_target=None,
                 log_step_size_reg_coefficient=0.05, iter_decay_coeff=0.75,
                 iter_offset=10, max_init_step_size_iters=100):
        &#34;&#34;&#34;
        Args:
            adapt_stat_target (float): Target value for the transition statistic
                being controlled during adaptation.
            adapt_stat_func (Callable[[Dict[str, numeric]], numeric]): Function
                which given a dictionary of transition statistics outputs the
                value of the statistic to control during adaptation. By default
                this is set to a function which simply selects the &#39;accept_stat&#39;
                value in the statistics dictionary.
            log_step_size_reg_target (float or None): Value to regularize the
                controlled output (logarithm of the integrator step size)
                towards. If `None` set to `log(10 * init_step_size)` where
                `init_step_size` is the initial &#39;reasonable&#39; step size found by
                a coarse search as recommended in Hoffman and Gelman (2014).
                This has the effect of giving the dual averaging algorithm a
                tendency towards testing step sizes larger than the initial
                value, with typically integrating with a larger step size having
                a lower computational cost.
            log_step_size_reg_coefficient (float): Coefficient controlling
                amount of regularisation of controlled output (logarithm of the
                integrator step size) towards `log_step_size_reg_target`.
                Defaults to 0.05 as recommended in Hoffman and Gelman (2014).
            iter_decay_coeff (float): Coefficient controlling exponent of
                decay in schedule weighting stochastic updates to smoothed log
                step size estimate. Should be in the interval (0.5, 1] to ensure
                asymptotic convergence of adaptation. A value of 1 gives equal
                weight to the whole history of updates while setting to a
                smaller value increasingly highly weights recent updates, giving
                a tendency to &#39;forget&#39; early updates. Defaults to 0.75 as
                recommended in Hoffman and Gelman (2014).
            iter_offset (int): Offset used for the iteration based weighting of
                the adaptation statistic error estimate. Should be set to a
                non-negative value. A value &gt; 0 has the effect of stabilising
                early iterations. Defaults to the value of 10 as recommended in
                Hoffman and Gelman (2014).
            max_init_step_size_iters (int): Maximum number of iterations to use
                in initial search for a reasonable step size with an
                `AdaptationError` exception raised if a suitable step size is
                not found within this many iterations.
        &#34;&#34;&#34;
        self.adapt_stat_target = adapt_stat_target
        if adapt_stat_func is None:
            def adapt_stat_func(stats): return stats[&#39;accept_stat&#39;]
        self.adapt_stat_func = adapt_stat_func
        self.log_step_size_reg_target = log_step_size_reg_target
        self.log_step_size_reg_coefficient = log_step_size_reg_coefficient
        self.iter_decay_coeff = iter_decay_coeff
        self.iter_offset = iter_offset
        self.max_init_step_size_iters = max_init_step_size_iters

    def initialize(self, chain_state, transition):
        integrator = transition.integrator
        system = transition.system
        adapt_state = {
            &#39;iter&#39;: 0,
            &#39;smoothed_log_step_size&#39;: 0.,
            &#39;adapt_stat_error&#39;: 0.,
        }
        init_step_size = (self._find_and_set_init_step_size(
            chain_state, system, integrator) if integrator.step_size is None
            else integrator.step_size)
        if self.log_step_size_reg_target is None:
            adapt_state[&#39;log_step_size_reg_target&#39;] = log(10 * init_step_size)
        else:
            adapt_state[&#39;log_step_size_reg_target&#39;] = (
                self.log_step_size_reg_target)
        return adapt_state

    def _find_and_set_init_step_size(self, state, system, integrator):
        &#34;&#34;&#34;Find initial step size by coarse search using single step statistics.

        Adaptation of Algorithm 4 in Hoffman and Gelman (2014).

        Compared to the Hoffman and Gelman algorithm, this version makes two
        changes:

          1. The absolute value of the change in Hamiltonian over a step being
             larger or smaller than log(2) is used to determine whether the step
             size is too big or small as opposed to the value of the equivalent
             Metropolis accept probability being larger or smaller than 0.5.
             Although a negative change in the Hamiltonian over a step of
             magnitude more than log(2) will lead to an accept probability of 1
             for the forward move, the corresponding reversed move will have an
             accept probability less than 0.5, and so a change in the
             Hamiltonian over a step of magnitude more than log(2) irrespective
             of the sign of the change is indicative of the minimum acceptance
             probability over both forward and reversed steps being less than
             0.5.
          2. To allow for integrators for which an integrator step may fail due
             to e.g. a convergence error in an iterative solver, the step size
             is also considered to be too big if any of the step sizes tried in
             the search result in a failed integrator step, with in this case
             the step size always being decreased on subsequent steps
             irrespective of the initial Hamiltonian error, until a integrator
             step successfully completes and the absolute value of the change in
             Hamiltonian is below the threshold of log(2) (corresponding to a
             minimum acceptance probability over forward and reversed steps of
             0.5).
        &#34;&#34;&#34;
        init_state = state.copy()
        h_init = system.h(init_state)
        integrator.step_size = 1
        delta_h_threshold = log(2)
        for s in range(self.max_init_step_size_iters):
            try:
                state = integrator.step(init_state)
                delta_h = abs(h_init - system.h(state))
                if s == 0:
                    step_size_too_big = delta_h &gt; delta_h_threshold
                if (step_size_too_big and delta_h &lt;= delta_h_threshold) or (
                        not step_size_too_big and delta_h &gt; delta_h_threshold):
                    return integrator.step_size
                elif step_size_too_big:
                    integrator.step_size /= 2
                else:
                    integrator.step_size *= 2
            except IntegratorError:
                step_size_too_big = True
                integrator.step_size /= 2
        raise AdaptationError(
            f&#39;Could not find reasonable initial step size in &#39;
            f&#39;{self.max_init_step_size_iters} iterations (final step size &#39;
            f&#39;{integrator.step_size}). A very large final step size may &#39;
            f&#39;indicate that the target distribution is improper such that the &#39;
            f&#39;negative log density is flat in one or more directions while a &#39;
            f&#39;very small final step size may indicate that the density function&#39;
            f&#39; is insufficiently smooth at the point initialized at.&#39;)

    def update(self, adapt_state, chain_state, trans_stats, transition):
        adapt_state[&#39;iter&#39;] += 1
        error_weight = 1 / (self.iter_offset + adapt_state[&#39;iter&#39;])
        adapt_state[&#39;adapt_stat_error&#39;] *= (1 - error_weight)
        adapt_state[&#39;adapt_stat_error&#39;] += error_weight * (
            self.adapt_stat_target - self.adapt_stat_func(trans_stats))
        smoothing_weight = (1 / adapt_state[&#39;iter&#39;])**self.iter_decay_coeff
        log_step_size = adapt_state[&#39;log_step_size_reg_target&#39;] - (
            adapt_state[&#39;adapt_stat_error&#39;] * adapt_state[&#39;iter&#39;]**0.5 /
            self.log_step_size_reg_coefficient)
        adapt_state[&#39;smoothed_log_step_size&#39;] *= (1 - smoothing_weight)
        adapt_state[&#39;smoothed_log_step_size&#39;] += (
            smoothing_weight * log_step_size)
        transition.integrator.step_size = exp(log_step_size)

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            transition.integrator.step_size = exp(
                adapt_state[&#39;smoothed_log_step_size&#39;])
        else:
            transition.integrator.step_size = sum(
                exp(a[&#39;smoothed_log_step_size&#39;])
                for a in adapt_state) / len(adapt_state)


class OnlineVarianceMetricAdapter(Adapter):
    &#34;&#34;&#34;Diagonal metric adapter using online variance estimates.

    Uses Welford&#39;s algorithm [1] to stably compute an online estimate of the
    sample variances of the chain state position components during sampling. If
    online estimates are available from multiple independent chains, the final
    variance estimate is calculated from the per-chain statistics using the
    parallel / batched incremental variance algorithm described by Chan et al.
    [2]. The variance estimates are optionally regularized towards a common
    scalar value, with increasing weight for small number of samples, to
    decrease the effect of noisy estimates for small sample sizes, following the
    approach in Stan [3]. The metric matrix representation is set to a diagonal
    matrix with diagonal elements corresponding to the reciprocal of the
    (regularized) variance estimates.

    References:

      1. Welford, B. P., 1962. Note on a method for calculating corrected sums
         of squares and products. Technometrics, 4(3), pp. 419–420.
      2. Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
         a pairwise algorithm for computing sample variances. Technical Report
         STAN-CS-79-773, Department of Computer Science, Stanford University.
      3. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
         Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
         Stan: A probabilistic programming language. Journal of Statistical
         Software, 76(1).
    &#34;&#34;&#34;

    def __init__(self, reg_iter_offset=5, reg_scale=1e-3):
        &#34;&#34;&#34;
        Args:
            reg_iter_offset (int): Iteration offset used for calculating
                iteration dependent weighting between regularisation target and
                current covariance estimate. Higher values cause stronger
                regularisation during initial iterations. A value of zero
                corresponds to no regularisation; this should only be used if
                the sample covariance is guaranteed to be positive definite.
            reg_scale (float): Positive scalar defining value variance estimates
                are regularized towards.
        &#34;&#34;&#34;
        self.reg_iter_offset = reg_iter_offset
        self.reg_scale = reg_scale

    def initialize(self, chain_state, transition):
        return {
            &#39;iter&#39;: 0,
            &#39;mean&#39;: np.zeros_like(chain_state.pos),
            &#39;sum_diff_sq&#39;: np.zeros_like(chain_state.pos)
        }

    def update(self, adapt_state, chain_state, trans_stats, transition):
        # Use Welford (1962) incremental algorithm to update statistics to
        # calculate online variance estimate
        # https://en.wikipedia.org/wiki/
        #   Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm
        adapt_state[&#39;iter&#39;] += 1
        pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
        adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
        adapt_state[&#39;sum_diff_sq&#39;] += pos_minus_mean * (
            chain_state.pos - adapt_state[&#39;mean&#39;])

    def _regularize_var_est(self, var_est, n_iter):
        &#34;&#34;&#34;Update variance estimates by regularizing towards common scalar.

        Performed in place to prevent further array allocations.
        &#34;&#34;&#34;
        if self.reg_iter_offset is not None and self.reg_iter_offset != 0:
            var_est *= n_iter / (self.reg_iter_offset + n_iter)
            var_est += self.reg_scale * (
                self.reg_iter_offset / (self.reg_iter_offset + n_iter))

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            n_iter = adapt_state[&#39;iter&#39;]
            var_est = adapt_state.pop(&#39;sum_diff_sq&#39;)
        else:
            # Use Chan et al. (1979) parallel variance estimation algorithm
            # to combine per-chain statistics
            # https://en.wikipedia.org/wiki/
            #    Algorithms_for_calculating_variance#Parallel_algorithm
            for i, a in enumerate(adapt_state):
                if i == 0:
                    n_iter = a[&#39;iter&#39;]
                    mean_est = a.pop(&#39;mean&#39;)
                    var_est = a.pop(&#39;sum_diff_sq&#39;)
                else:
                    n_iter_prev = n_iter
                    n_iter += a[&#39;iter&#39;]
                    mean_diff = mean_est - a[&#39;mean&#39;]
                    mean_est *= n_iter_prev
                    mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                    mean_est /= n_iter
                    var_est += a[&#39;sum_diff_sq&#39;]
                    var_est += mean_diff**2 * (a[&#39;iter&#39;] * n_iter_prev) / n_iter
        if n_iter &lt; 2:
            raise AdaptationError(
                &#39;At least two chain samples required to compute a variance &#39;
                &#39;estimates.&#39;)
        var_est /= (n_iter - 1)
        self._regularize_var_est(var_est, n_iter)
        transition.system.metric = PositiveDiagonalMatrix(var_est).inv


class OnlineCovarianceMetricAdapter(Adapter):
    &#34;&#34;&#34;Dense metric adapter using online covariance estimates.

    Uses Welford&#39;s algorithm [1] to stably compute an online estimate of the
    sample covariane matrix of the chain state position components during
    sampling. If online estimates are available from multiple independent
    chains, the final covariance matrix estimate is calculated from the
    per-chain statistics using a covariance variant due to Schubert and Gertz
    [2] of the parallel / batched incremental variance algorithm described by
    Chan et al. [3]. The covariance matrix estimates are optionally regularized
    towards a scaled identity matrix, with increasing weight for small number of
    samples, to decrease the effect of noisy estimates for small sample sizes,
    following the approach in Stan [4]. The metric matrix representation is set
    to a dense positive definite matrix corresponding to the inverse of the
    (regularized) covariance matrix estimate.


    References:

      1. Welford, B. P., 1962. Note on a method for calculating corrected sums
         of squares and products. Technometrics, 4(3), pp. 419–420.
      2. Schubert, E. and Gertz, M., 2018. Numerically stable parallel
         computation of (co-)variance. ACM. p. 10. doi:10.1145/3221269.3223036.
      3. Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
         a pairwise algorithm for computing sample variances. Technical Report
         STAN-CS-79-773, Department of Computer Science, Stanford University.
      4. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
         Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
         Stan: A probabilistic programming language. Journal of Statistical
         Software, 76(1).
    &#34;&#34;&#34;

    def __init__(self, reg_iter_offset=5, reg_scale=1e-3):
        &#34;&#34;&#34;
        Args:
            reg_iter_offset (int): Iteration offset used for calculating
                iteration dependent weighting between regularisation target and
                current covariance estimate. Higher values cause stronger
                regularisation during initial iterations.
            reg_scale (float): Positive scalar defining value variance estimates
                are regularized towards.
        &#34;&#34;&#34;
        self.reg_iter_offset = reg_iter_offset
        self.reg_scale = reg_scale

    def initialize(self, chain_state, transition):
        dim_pos = chain_state.pos.shape[0]
        dtype = chain_state.pos.dtype
        return {
            &#39;iter&#39;: 0,
            &#39;mean&#39;: np.zeros(shape=(dim_pos,), dtype=dtype),
            &#39;sum_diff_outer&#39;: np.zeros(shape=(dim_pos, dim_pos), dtype=dtype)
        }

    def update(self, adapt_state, chain_state, trans_stats, transition):
        # Use Welford (1962) incremental algorithm to update statistics to
        # calculate online covariance estimate
        # https://en.wikipedia.org/wiki/
        #  Algorithms_for_calculating_variance#Online
        adapt_state[&#39;iter&#39;] += 1
        pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
        adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
        adapt_state[&#39;sum_diff_outer&#39;] += pos_minus_mean[None, :] * (
            chain_state.pos - adapt_state[&#39;mean&#39;])[:, None]

    def _regularize_covar_est(self, covar_est, n_iter):
        &#34;&#34;&#34;Update covariance estimate by regularising towards identity.

        Performed in place to prevent further array allocations.
        &#34;&#34;&#34;
        covar_est *= (n_iter / (self.reg_iter_offset + n_iter))
        covar_est_diagonal = np.einsum(&#39;ii-&gt;i&#39;, covar_est)
        covar_est_diagonal += self.reg_scale * (
            self.reg_iter_offset / (self.reg_iter_offset + n_iter))

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            n_iter = adapt_state[&#39;iter&#39;]
            covar_est = adapt_state.pop(&#39;sum_diff_outer&#39;)
        else:
            # Use Schubert and Gertz (2018) parallel covariance estimation
            # algorithm to combine per-chain statistics
            for i, a in enumerate(adapt_state):
                if i == 0:
                    n_iter = a[&#39;iter&#39;]
                    mean_est = a.pop(&#39;mean&#39;)
                    covar_est = a.pop(&#39;sum_diff_outer&#39;)
                else:
                    n_iter_prev = n_iter
                    n_iter += a[&#39;iter&#39;]
                    mean_diff = mean_est - a[&#39;mean&#39;]
                    mean_est *= n_iter_prev
                    mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                    mean_est /= n_iter
                    covar_est += a[&#39;sum_diff_outer&#39;]
                    covar_est += np.outer(mean_diff, mean_diff) * (
                        a[&#39;iter&#39;] * n_iter_prev) / n_iter
        if n_iter &lt; 2:
            raise AdaptationError(
                &#39;At least two chain samples required to compute a variance &#39;
                &#39;estimates.&#39;)
        covar_est /= (n_iter - 1)
        self._regularize_covar_est(covar_est, n_iter)
        transition.system.metric = DensePositiveDefiniteMatrix(covar_est).inv</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="mici.adapters.Adapter"><code class="flex name class">
<span>class <span class="ident">Adapter</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Abstract adapter for implementing schemes to adapt transition parameters.</p>
<p>Adaptation schemes are assumed to be based on updating a collection of
adaptation variables (collectively termed the adapter state here) after
each chain transition based on the sampled chain state and/or statistics of
the transition such as an acceptance probability statistic. After completing
a chain of one or more adaptive transitions, the final adapter state may be
used to perform a final update to the transition parameters.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L11-L74" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Adapter(ABC):
    &#34;&#34;&#34;Abstract adapter for implementing schemes to adapt transition parameters.

    Adaptation schemes are assumed to be based on updating a collection of
    adaptation variables (collectively termed the adapter state here) after
    each chain transition based on the sampled chain state and/or statistics of
    the transition such as an acceptance probability statistic. After completing
    a chain of one or more adaptive transitions, the final adapter state may be
    used to perform a final update to the transition parameters.
    &#34;&#34;&#34;

    @abstractmethod
    def initialize(self, chain_state, transition):
        &#34;&#34;&#34;Initialize adapter state prior to starting adaptive transitions.

        Args:
            chain_state (mici.states.ChainState): Initial chain state adaptive
                transition will be started from. May be used to calculate
                initial adapter state but should not be mutated by method.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects may be
                updated in-place by the method.

        Returns:
            adapt_state (Dict[str, Any]): Initial adapter state.
        &#34;&#34;&#34;

    @abstractmethod
    def update(self, adapt_state, chain_state, trans_stats, transition):
        &#34;&#34;&#34;Update adapter state after sampling transition being adapted.

        Args:
            adapt_state (Dict[str, Any]): Current adapter state. Entries will
                be updated in-place by the method.
            chain_state (mici.states.ChainState): Current chain state following
                sampling from transition being adapted. May be used to calculate
                adapter state updates but should not be mutated by method.
            trans_stats (Dict[str, numeric]): Dictionary of statistics
                associated with transition being adapted. May be used to
                calculate adapter state updates but should not be mutated by
                method.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects may be
                updated in-place by the method.
        &#34;&#34;&#34;

    @abstractmethod
    def finalize(self, adapt_state, transition):
        &#34;&#34;&#34;Update transition parameters based on final adapter state or states.

        Optionally, if multiple adapter states are available, e.g. from a set of
        independent adaptive chains, then these adaptation information from all
        the chains may be combined to set the transition parameter(s).

        Args:
            adapt_state (Dict[str, Any] or List[Dict[str, Any]]): Final adapter
                state or a list of adapter states. Arrays / buffers associated
                with the adapter state entries may be recycled to reduce memory
                usage - if so the corresponding entries will be removed from
                the adapter state dictionary / dictionaries.
            transition (mici.transitions.Transition): Markov transition being
                adapted. Attributes of the transition or child objects will be
                updated in-place by the method.
        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="mici.adapters.DualAveragingStepSizeAdapter" href="#mici.adapters.DualAveragingStepSizeAdapter">DualAveragingStepSizeAdapter</a></li>
<li><a title="mici.adapters.OnlineVarianceMetricAdapter" href="#mici.adapters.OnlineVarianceMetricAdapter">OnlineVarianceMetricAdapter</a></li>
<li><a title="mici.adapters.OnlineCovarianceMetricAdapter" href="#mici.adapters.OnlineCovarianceMetricAdapter">OnlineCovarianceMetricAdapter</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mici.adapters.Adapter.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, chain_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize adapter state prior to starting adaptive transitions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Initial chain state adaptive
transition will be started from. May be used to calculate
initial adapter state but should not be mutated by method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Initial adapter state.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L22-L36" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@abstractmethod
def initialize(self, chain_state, transition):
    &#34;&#34;&#34;Initialize adapter state prior to starting adaptive transitions.

    Args:
        chain_state (mici.states.ChainState): Initial chain state adaptive
            transition will be started from. May be used to calculate
            initial adapter state but should not be mutated by method.
        transition (mici.transitions.Transition): Markov transition being
            adapted. Attributes of the transition or child objects may be
            updated in-place by the method.

    Returns:
        adapt_state (Dict[str, Any]): Initial adapter state.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="mici.adapters.Adapter.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, adapt_state, chain_state, trans_stats, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update adapter state after sampling transition being adapted.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Current adapter state. Entries will
be updated in-place by the method.</dd>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Current chain state following
sampling from transition being adapted. May be used to calculate
adapter state updates but should not be mutated by method.</dd>
<dt><strong><code>trans_stats</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>numeric</code>]</dt>
<dd>Dictionary of statistics
associated with transition being adapted. May be used to
calculate adapter state updates but should not be mutated by
method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L38-L55" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@abstractmethod
def update(self, adapt_state, chain_state, trans_stats, transition):
    &#34;&#34;&#34;Update adapter state after sampling transition being adapted.

    Args:
        adapt_state (Dict[str, Any]): Current adapter state. Entries will
            be updated in-place by the method.
        chain_state (mici.states.ChainState): Current chain state following
            sampling from transition being adapted. May be used to calculate
            adapter state updates but should not be mutated by method.
        trans_stats (Dict[str, numeric]): Dictionary of statistics
            associated with transition being adapted. May be used to
            calculate adapter state updates but should not be mutated by
            method.
        transition (mici.transitions.Transition): Markov transition being
            adapted. Attributes of the transition or child objects may be
            updated in-place by the method.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
<dt id="mici.adapters.Adapter.finalize"><code class="name flex">
<span>def <span class="ident">finalize</span></span>(<span>self, adapt_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update transition parameters based on final adapter state or states.</p>
<p>Optionally, if multiple adapter states are available, e.g. from a set of
independent adaptive chains, then these adaptation information from all
the chains may be combined to set the transition parameter(s).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>] or <code>List</code>[<code>Dict</code>[<code>str</code>, <code>Any</code>]]</dt>
<dd>Final adapter
state or a list of adapter states. Arrays / buffers associated
with the adapter state entries may be recycled to reduce memory
usage - if so the corresponding entries will be removed from
the adapter state dictionary / dictionaries.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects will be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L57-L74" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@abstractmethod
def finalize(self, adapt_state, transition):
    &#34;&#34;&#34;Update transition parameters based on final adapter state or states.

    Optionally, if multiple adapter states are available, e.g. from a set of
    independent adaptive chains, then these adaptation information from all
    the chains may be combined to set the transition parameter(s).

    Args:
        adapt_state (Dict[str, Any] or List[Dict[str, Any]]): Final adapter
            state or a list of adapter states. Arrays / buffers associated
            with the adapter state entries may be recycled to reduce memory
            usage - if so the corresponding entries will be removed from
            the adapter state dictionary / dictionaries.
        transition (mici.transitions.Transition): Markov transition being
            adapted. Attributes of the transition or child objects will be
            updated in-place by the method.
    &#34;&#34;&#34;</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mici.adapters.DualAveragingStepSizeAdapter"><code class="flex name class">
<span>class <span class="ident">DualAveragingStepSizeAdapter</span></span>
<span>(</span><span>adapt_stat_target=0.8, adapt_stat_func=None, log_step_size_reg_target=None, log_step_size_reg_coefficient=0.05, iter_decay_coeff=0.75, iter_offset=10, max_init_step_size_iters=100)</span>
</code></dt>
<dd>
<section class="desc"><p>Dual averaging integrator step size adapter.</p>
<p>Implementation of the dual algorithm step size adaptation algorithm
described in [1], a modified version of the stochastic optimisation scheme
of [2]. By default the adaptation is performed to control the <code>accept_prob</code>
statistic of an integration transition to be close to a target value but
the statistic adapted on can be altered by changing the <code>adapt_stat_func</code>.</p>
<h2 id="references">References</h2>
<ol>
<li>Hoffman, M.D. and Gelman, A., 2014. The No-U-turn sampler:
adaptively setting path lengths in Hamiltonian Monte Carlo.
Journal of Machine Learning Research, 15(1), pp.1593-1623.</li>
<li>Nesterov, Y., 2009. Primal-dual subgradient methods for convex
problems. Mathematical programming 120(1), pp.221-259.</li>
</ol>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_stat_target</code></strong> :&ensp;<code>float</code></dt>
<dd>Target value for the transition statistic
being controlled during adaptation.</dd>
<dt><strong><code>adapt_stat_func</code></strong> :&ensp;<code>Callable</code>[[<code>Dict</code>[<code>str</code>, <code>numeric</code>]], <code>numeric</code>]</dt>
<dd>Function
which given a dictionary of transition statistics outputs the
value of the statistic to control during adaptation. By default
this is set to a function which simply selects the 'accept_stat'
value in the statistics dictionary.</dd>
<dt><strong><code>log_step_size_reg_target</code></strong> :&ensp;<code>float</code> or <code>None</code></dt>
<dd>Value to regularize the
controlled output (logarithm of the integrator step size)
towards. If <code>None</code> set to <code>log(10 * init_step_size)</code> where
<code>init_step_size</code> is the initial 'reasonable' step size found by
a coarse search as recommended in Hoffman and Gelman (2014).
This has the effect of giving the dual averaging algorithm a
tendency towards testing step sizes larger than the initial
value, with typically integrating with a larger step size having
a lower computational cost.</dd>
<dt><strong><code>log_step_size_reg_coefficient</code></strong> :&ensp;<code>float</code></dt>
<dd>Coefficient controlling
amount of regularisation of controlled output (logarithm of the
integrator step size) towards <code>log_step_size_reg_target</code>.
Defaults to 0.05 as recommended in Hoffman and Gelman (2014).</dd>
<dt><strong><code>iter_decay_coeff</code></strong> :&ensp;<code>float</code></dt>
<dd>Coefficient controlling exponent of
decay in schedule weighting stochastic updates to smoothed log
step size estimate. Should be in the interval (0.5, 1] to ensure
asymptotic convergence of adaptation. A value of 1 gives equal
weight to the whole history of updates while setting to a
smaller value increasingly highly weights recent updates, giving
a tendency to 'forget' early updates. Defaults to 0.75 as
recommended in Hoffman and Gelman (2014).</dd>
<dt><strong><code>iter_offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Offset used for the iteration based weighting of
the adaptation statistic error estimate. Should be set to a
non-negative value. A value &gt; 0 has the effect of stabilising
early iterations. Defaults to the value of 10 as recommended in
Hoffman and Gelman (2014).</dd>
<dt><strong><code>max_init_step_size_iters</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of iterations to use
in initial search for a reasonable step size with an
<code>AdaptationError</code> exception raised if a suitable step size is
not found within this many iterations.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L77-L250" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class DualAveragingStepSizeAdapter(Adapter):
    &#34;&#34;&#34;Dual averaging integrator step size adapter.

    Implementation of the dual algorithm step size adaptation algorithm
    described in [1], a modified version of the stochastic optimisation scheme
    of [2]. By default the adaptation is performed to control the `accept_prob`
    statistic of an integration transition to be close to a target value but
    the statistic adapted on can be altered by changing the `adapt_stat_func`.


    References:

      1. Hoffman, M.D. and Gelman, A., 2014. The No-U-turn sampler:
         adaptively setting path lengths in Hamiltonian Monte Carlo.
         Journal of Machine Learning Research, 15(1), pp.1593-1623.
      2. Nesterov, Y., 2009. Primal-dual subgradient methods for convex
         problems. Mathematical programming 120(1), pp.221-259.
    &#34;&#34;&#34;

    def __init__(self, adapt_stat_target=0.8, adapt_stat_func=None,
                 log_step_size_reg_target=None,
                 log_step_size_reg_coefficient=0.05, iter_decay_coeff=0.75,
                 iter_offset=10, max_init_step_size_iters=100):
        &#34;&#34;&#34;
        Args:
            adapt_stat_target (float): Target value for the transition statistic
                being controlled during adaptation.
            adapt_stat_func (Callable[[Dict[str, numeric]], numeric]): Function
                which given a dictionary of transition statistics outputs the
                value of the statistic to control during adaptation. By default
                this is set to a function which simply selects the &#39;accept_stat&#39;
                value in the statistics dictionary.
            log_step_size_reg_target (float or None): Value to regularize the
                controlled output (logarithm of the integrator step size)
                towards. If `None` set to `log(10 * init_step_size)` where
                `init_step_size` is the initial &#39;reasonable&#39; step size found by
                a coarse search as recommended in Hoffman and Gelman (2014).
                This has the effect of giving the dual averaging algorithm a
                tendency towards testing step sizes larger than the initial
                value, with typically integrating with a larger step size having
                a lower computational cost.
            log_step_size_reg_coefficient (float): Coefficient controlling
                amount of regularisation of controlled output (logarithm of the
                integrator step size) towards `log_step_size_reg_target`.
                Defaults to 0.05 as recommended in Hoffman and Gelman (2014).
            iter_decay_coeff (float): Coefficient controlling exponent of
                decay in schedule weighting stochastic updates to smoothed log
                step size estimate. Should be in the interval (0.5, 1] to ensure
                asymptotic convergence of adaptation. A value of 1 gives equal
                weight to the whole history of updates while setting to a
                smaller value increasingly highly weights recent updates, giving
                a tendency to &#39;forget&#39; early updates. Defaults to 0.75 as
                recommended in Hoffman and Gelman (2014).
            iter_offset (int): Offset used for the iteration based weighting of
                the adaptation statistic error estimate. Should be set to a
                non-negative value. A value &gt; 0 has the effect of stabilising
                early iterations. Defaults to the value of 10 as recommended in
                Hoffman and Gelman (2014).
            max_init_step_size_iters (int): Maximum number of iterations to use
                in initial search for a reasonable step size with an
                `AdaptationError` exception raised if a suitable step size is
                not found within this many iterations.
        &#34;&#34;&#34;
        self.adapt_stat_target = adapt_stat_target
        if adapt_stat_func is None:
            def adapt_stat_func(stats): return stats[&#39;accept_stat&#39;]
        self.adapt_stat_func = adapt_stat_func
        self.log_step_size_reg_target = log_step_size_reg_target
        self.log_step_size_reg_coefficient = log_step_size_reg_coefficient
        self.iter_decay_coeff = iter_decay_coeff
        self.iter_offset = iter_offset
        self.max_init_step_size_iters = max_init_step_size_iters

    def initialize(self, chain_state, transition):
        integrator = transition.integrator
        system = transition.system
        adapt_state = {
            &#39;iter&#39;: 0,
            &#39;smoothed_log_step_size&#39;: 0.,
            &#39;adapt_stat_error&#39;: 0.,
        }
        init_step_size = (self._find_and_set_init_step_size(
            chain_state, system, integrator) if integrator.step_size is None
            else integrator.step_size)
        if self.log_step_size_reg_target is None:
            adapt_state[&#39;log_step_size_reg_target&#39;] = log(10 * init_step_size)
        else:
            adapt_state[&#39;log_step_size_reg_target&#39;] = (
                self.log_step_size_reg_target)
        return adapt_state

    def _find_and_set_init_step_size(self, state, system, integrator):
        &#34;&#34;&#34;Find initial step size by coarse search using single step statistics.

        Adaptation of Algorithm 4 in Hoffman and Gelman (2014).

        Compared to the Hoffman and Gelman algorithm, this version makes two
        changes:

          1. The absolute value of the change in Hamiltonian over a step being
             larger or smaller than log(2) is used to determine whether the step
             size is too big or small as opposed to the value of the equivalent
             Metropolis accept probability being larger or smaller than 0.5.
             Although a negative change in the Hamiltonian over a step of
             magnitude more than log(2) will lead to an accept probability of 1
             for the forward move, the corresponding reversed move will have an
             accept probability less than 0.5, and so a change in the
             Hamiltonian over a step of magnitude more than log(2) irrespective
             of the sign of the change is indicative of the minimum acceptance
             probability over both forward and reversed steps being less than
             0.5.
          2. To allow for integrators for which an integrator step may fail due
             to e.g. a convergence error in an iterative solver, the step size
             is also considered to be too big if any of the step sizes tried in
             the search result in a failed integrator step, with in this case
             the step size always being decreased on subsequent steps
             irrespective of the initial Hamiltonian error, until a integrator
             step successfully completes and the absolute value of the change in
             Hamiltonian is below the threshold of log(2) (corresponding to a
             minimum acceptance probability over forward and reversed steps of
             0.5).
        &#34;&#34;&#34;
        init_state = state.copy()
        h_init = system.h(init_state)
        integrator.step_size = 1
        delta_h_threshold = log(2)
        for s in range(self.max_init_step_size_iters):
            try:
                state = integrator.step(init_state)
                delta_h = abs(h_init - system.h(state))
                if s == 0:
                    step_size_too_big = delta_h &gt; delta_h_threshold
                if (step_size_too_big and delta_h &lt;= delta_h_threshold) or (
                        not step_size_too_big and delta_h &gt; delta_h_threshold):
                    return integrator.step_size
                elif step_size_too_big:
                    integrator.step_size /= 2
                else:
                    integrator.step_size *= 2
            except IntegratorError:
                step_size_too_big = True
                integrator.step_size /= 2
        raise AdaptationError(
            f&#39;Could not find reasonable initial step size in &#39;
            f&#39;{self.max_init_step_size_iters} iterations (final step size &#39;
            f&#39;{integrator.step_size}). A very large final step size may &#39;
            f&#39;indicate that the target distribution is improper such that the &#39;
            f&#39;negative log density is flat in one or more directions while a &#39;
            f&#39;very small final step size may indicate that the density function&#39;
            f&#39; is insufficiently smooth at the point initialized at.&#39;)

    def update(self, adapt_state, chain_state, trans_stats, transition):
        adapt_state[&#39;iter&#39;] += 1
        error_weight = 1 / (self.iter_offset + adapt_state[&#39;iter&#39;])
        adapt_state[&#39;adapt_stat_error&#39;] *= (1 - error_weight)
        adapt_state[&#39;adapt_stat_error&#39;] += error_weight * (
            self.adapt_stat_target - self.adapt_stat_func(trans_stats))
        smoothing_weight = (1 / adapt_state[&#39;iter&#39;])**self.iter_decay_coeff
        log_step_size = adapt_state[&#39;log_step_size_reg_target&#39;] - (
            adapt_state[&#39;adapt_stat_error&#39;] * adapt_state[&#39;iter&#39;]**0.5 /
            self.log_step_size_reg_coefficient)
        adapt_state[&#39;smoothed_log_step_size&#39;] *= (1 - smoothing_weight)
        adapt_state[&#39;smoothed_log_step_size&#39;] += (
            smoothing_weight * log_step_size)
        transition.integrator.step_size = exp(log_step_size)

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            transition.integrator.step_size = exp(
                adapt_state[&#39;smoothed_log_step_size&#39;])
        else:
            transition.integrator.step_size = sum(
                exp(a[&#39;smoothed_log_step_size&#39;])
                for a in adapt_state) / len(adapt_state)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mici.adapters.Adapter" href="#mici.adapters.Adapter">Adapter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mici.adapters.DualAveragingStepSizeAdapter.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, chain_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize adapter state prior to starting adaptive transitions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Initial chain state adaptive
transition will be started from. May be used to calculate
initial adapter state but should not be mutated by method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Initial adapter state.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L150-L166" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def initialize(self, chain_state, transition):
    integrator = transition.integrator
    system = transition.system
    adapt_state = {
        &#39;iter&#39;: 0,
        &#39;smoothed_log_step_size&#39;: 0.,
        &#39;adapt_stat_error&#39;: 0.,
    }
    init_step_size = (self._find_and_set_init_step_size(
        chain_state, system, integrator) if integrator.step_size is None
        else integrator.step_size)
    if self.log_step_size_reg_target is None:
        adapt_state[&#39;log_step_size_reg_target&#39;] = log(10 * init_step_size)
    else:
        adapt_state[&#39;log_step_size_reg_target&#39;] = (
            self.log_step_size_reg_target)
    return adapt_state</code></pre>
</details>
</dd>
<dt id="mici.adapters.DualAveragingStepSizeAdapter.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, adapt_state, chain_state, trans_stats, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update adapter state after sampling transition being adapted.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Current adapter state. Entries will
be updated in-place by the method.</dd>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Current chain state following
sampling from transition being adapted. May be used to calculate
adapter state updates but should not be mutated by method.</dd>
<dt><strong><code>trans_stats</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>numeric</code>]</dt>
<dd>Dictionary of statistics
associated with transition being adapted. May be used to
calculate adapter state updates but should not be mutated by
method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L228-L241" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update(self, adapt_state, chain_state, trans_stats, transition):
    adapt_state[&#39;iter&#39;] += 1
    error_weight = 1 / (self.iter_offset + adapt_state[&#39;iter&#39;])
    adapt_state[&#39;adapt_stat_error&#39;] *= (1 - error_weight)
    adapt_state[&#39;adapt_stat_error&#39;] += error_weight * (
        self.adapt_stat_target - self.adapt_stat_func(trans_stats))
    smoothing_weight = (1 / adapt_state[&#39;iter&#39;])**self.iter_decay_coeff
    log_step_size = adapt_state[&#39;log_step_size_reg_target&#39;] - (
        adapt_state[&#39;adapt_stat_error&#39;] * adapt_state[&#39;iter&#39;]**0.5 /
        self.log_step_size_reg_coefficient)
    adapt_state[&#39;smoothed_log_step_size&#39;] *= (1 - smoothing_weight)
    adapt_state[&#39;smoothed_log_step_size&#39;] += (
        smoothing_weight * log_step_size)
    transition.integrator.step_size = exp(log_step_size)</code></pre>
</details>
</dd>
<dt id="mici.adapters.DualAveragingStepSizeAdapter.finalize"><code class="name flex">
<span>def <span class="ident">finalize</span></span>(<span>self, adapt_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update transition parameters based on final adapter state or states.</p>
<p>Optionally, if multiple adapter states are available, e.g. from a set of
independent adaptive chains, then these adaptation information from all
the chains may be combined to set the transition parameter(s).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>] or <code>List</code>[<code>Dict</code>[<code>str</code>, <code>Any</code>]]</dt>
<dd>Final adapter
state or a list of adapter states. Arrays / buffers associated
with the adapter state entries may be recycled to reduce memory
usage - if so the corresponding entries will be removed from
the adapter state dictionary / dictionaries.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects will be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L243-L250" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def finalize(self, adapt_state, transition):
    if isinstance(adapt_state, dict):
        transition.integrator.step_size = exp(
            adapt_state[&#39;smoothed_log_step_size&#39;])
    else:
        transition.integrator.step_size = sum(
            exp(a[&#39;smoothed_log_step_size&#39;])
            for a in adapt_state) / len(adapt_state)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mici.adapters.OnlineVarianceMetricAdapter"><code class="flex name class">
<span>class <span class="ident">OnlineVarianceMetricAdapter</span></span>
<span>(</span><span>reg_iter_offset=5, reg_scale=0.001)</span>
</code></dt>
<dd>
<section class="desc"><p>Diagonal metric adapter using online variance estimates.</p>
<p>Uses Welford's algorithm [1] to stably compute an online estimate of the
sample variances of the chain state position components during sampling. If
online estimates are available from multiple independent chains, the final
variance estimate is calculated from the per-chain statistics using the
parallel / batched incremental variance algorithm described by Chan et al.
[2]. The variance estimates are optionally regularized towards a common
scalar value, with increasing weight for small number of samples, to
decrease the effect of noisy estimates for small sample sizes, following the
approach in Stan [3]. The metric matrix representation is set to a diagonal
matrix with diagonal elements corresponding to the reciprocal of the
(regularized) variance estimates.</p>
<h2 id="references">References</h2>
<ol>
<li>Welford, B. P., 1962. Note on a method for calculating corrected sums
of squares and products. Technometrics, 4(3), pp. 419–420.</li>
<li>Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
a pairwise algorithm for computing sample variances. Technical Report
STAN-CS-79-773, Department of Computer Science, Stanford University.</li>
<li>Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
Stan: A probabilistic programming language. Journal of Statistical
Software, 76(1).</li>
</ol>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reg_iter_offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Iteration offset used for calculating
iteration dependent weighting between regularisation target and
current covariance estimate. Higher values cause stronger
regularisation during initial iterations. A value of zero
corresponds to no regularisation; this should only be used if
the sample covariance is guaranteed to be positive definite.</dd>
<dt><strong><code>reg_scale</code></strong> :&ensp;<code>float</code></dt>
<dd>Positive scalar defining value variance estimates
are regularized towards.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L253-L353" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class OnlineVarianceMetricAdapter(Adapter):
    &#34;&#34;&#34;Diagonal metric adapter using online variance estimates.

    Uses Welford&#39;s algorithm [1] to stably compute an online estimate of the
    sample variances of the chain state position components during sampling. If
    online estimates are available from multiple independent chains, the final
    variance estimate is calculated from the per-chain statistics using the
    parallel / batched incremental variance algorithm described by Chan et al.
    [2]. The variance estimates are optionally regularized towards a common
    scalar value, with increasing weight for small number of samples, to
    decrease the effect of noisy estimates for small sample sizes, following the
    approach in Stan [3]. The metric matrix representation is set to a diagonal
    matrix with diagonal elements corresponding to the reciprocal of the
    (regularized) variance estimates.

    References:

      1. Welford, B. P., 1962. Note on a method for calculating corrected sums
         of squares and products. Technometrics, 4(3), pp. 419–420.
      2. Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
         a pairwise algorithm for computing sample variances. Technical Report
         STAN-CS-79-773, Department of Computer Science, Stanford University.
      3. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
         Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
         Stan: A probabilistic programming language. Journal of Statistical
         Software, 76(1).
    &#34;&#34;&#34;

    def __init__(self, reg_iter_offset=5, reg_scale=1e-3):
        &#34;&#34;&#34;
        Args:
            reg_iter_offset (int): Iteration offset used for calculating
                iteration dependent weighting between regularisation target and
                current covariance estimate. Higher values cause stronger
                regularisation during initial iterations. A value of zero
                corresponds to no regularisation; this should only be used if
                the sample covariance is guaranteed to be positive definite.
            reg_scale (float): Positive scalar defining value variance estimates
                are regularized towards.
        &#34;&#34;&#34;
        self.reg_iter_offset = reg_iter_offset
        self.reg_scale = reg_scale

    def initialize(self, chain_state, transition):
        return {
            &#39;iter&#39;: 0,
            &#39;mean&#39;: np.zeros_like(chain_state.pos),
            &#39;sum_diff_sq&#39;: np.zeros_like(chain_state.pos)
        }

    def update(self, adapt_state, chain_state, trans_stats, transition):
        # Use Welford (1962) incremental algorithm to update statistics to
        # calculate online variance estimate
        # https://en.wikipedia.org/wiki/
        #   Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm
        adapt_state[&#39;iter&#39;] += 1
        pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
        adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
        adapt_state[&#39;sum_diff_sq&#39;] += pos_minus_mean * (
            chain_state.pos - adapt_state[&#39;mean&#39;])

    def _regularize_var_est(self, var_est, n_iter):
        &#34;&#34;&#34;Update variance estimates by regularizing towards common scalar.

        Performed in place to prevent further array allocations.
        &#34;&#34;&#34;
        if self.reg_iter_offset is not None and self.reg_iter_offset != 0:
            var_est *= n_iter / (self.reg_iter_offset + n_iter)
            var_est += self.reg_scale * (
                self.reg_iter_offset / (self.reg_iter_offset + n_iter))

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            n_iter = adapt_state[&#39;iter&#39;]
            var_est = adapt_state.pop(&#39;sum_diff_sq&#39;)
        else:
            # Use Chan et al. (1979) parallel variance estimation algorithm
            # to combine per-chain statistics
            # https://en.wikipedia.org/wiki/
            #    Algorithms_for_calculating_variance#Parallel_algorithm
            for i, a in enumerate(adapt_state):
                if i == 0:
                    n_iter = a[&#39;iter&#39;]
                    mean_est = a.pop(&#39;mean&#39;)
                    var_est = a.pop(&#39;sum_diff_sq&#39;)
                else:
                    n_iter_prev = n_iter
                    n_iter += a[&#39;iter&#39;]
                    mean_diff = mean_est - a[&#39;mean&#39;]
                    mean_est *= n_iter_prev
                    mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                    mean_est /= n_iter
                    var_est += a[&#39;sum_diff_sq&#39;]
                    var_est += mean_diff**2 * (a[&#39;iter&#39;] * n_iter_prev) / n_iter
        if n_iter &lt; 2:
            raise AdaptationError(
                &#39;At least two chain samples required to compute a variance &#39;
                &#39;estimates.&#39;)
        var_est /= (n_iter - 1)
        self._regularize_var_est(var_est, n_iter)
        transition.system.metric = PositiveDiagonalMatrix(var_est).inv</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mici.adapters.Adapter" href="#mici.adapters.Adapter">Adapter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mici.adapters.OnlineVarianceMetricAdapter.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, chain_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize adapter state prior to starting adaptive transitions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Initial chain state adaptive
transition will be started from. May be used to calculate
initial adapter state but should not be mutated by method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Initial adapter state.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L296-L301" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def initialize(self, chain_state, transition):
    return {
        &#39;iter&#39;: 0,
        &#39;mean&#39;: np.zeros_like(chain_state.pos),
        &#39;sum_diff_sq&#39;: np.zeros_like(chain_state.pos)
    }</code></pre>
</details>
</dd>
<dt id="mici.adapters.OnlineVarianceMetricAdapter.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, adapt_state, chain_state, trans_stats, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update adapter state after sampling transition being adapted.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Current adapter state. Entries will
be updated in-place by the method.</dd>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Current chain state following
sampling from transition being adapted. May be used to calculate
adapter state updates but should not be mutated by method.</dd>
<dt><strong><code>trans_stats</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>numeric</code>]</dt>
<dd>Dictionary of statistics
associated with transition being adapted. May be used to
calculate adapter state updates but should not be mutated by
method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L303-L312" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update(self, adapt_state, chain_state, trans_stats, transition):
    # Use Welford (1962) incremental algorithm to update statistics to
    # calculate online variance estimate
    # https://en.wikipedia.org/wiki/
    #   Algorithms_for_calculating_variance#Welford&#39;s_online_algorithm
    adapt_state[&#39;iter&#39;] += 1
    pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
    adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
    adapt_state[&#39;sum_diff_sq&#39;] += pos_minus_mean * (
        chain_state.pos - adapt_state[&#39;mean&#39;])</code></pre>
</details>
</dd>
<dt id="mici.adapters.OnlineVarianceMetricAdapter.finalize"><code class="name flex">
<span>def <span class="ident">finalize</span></span>(<span>self, adapt_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update transition parameters based on final adapter state or states.</p>
<p>Optionally, if multiple adapter states are available, e.g. from a set of
independent adaptive chains, then these adaptation information from all
the chains may be combined to set the transition parameter(s).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>] or <code>List</code>[<code>Dict</code>[<code>str</code>, <code>Any</code>]]</dt>
<dd>Final adapter
state or a list of adapter states. Arrays / buffers associated
with the adapter state entries may be recycled to reduce memory
usage - if so the corresponding entries will be removed from
the adapter state dictionary / dictionaries.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects will be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L324-L353" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def finalize(self, adapt_state, transition):
    if isinstance(adapt_state, dict):
        n_iter = adapt_state[&#39;iter&#39;]
        var_est = adapt_state.pop(&#39;sum_diff_sq&#39;)
    else:
        # Use Chan et al. (1979) parallel variance estimation algorithm
        # to combine per-chain statistics
        # https://en.wikipedia.org/wiki/
        #    Algorithms_for_calculating_variance#Parallel_algorithm
        for i, a in enumerate(adapt_state):
            if i == 0:
                n_iter = a[&#39;iter&#39;]
                mean_est = a.pop(&#39;mean&#39;)
                var_est = a.pop(&#39;sum_diff_sq&#39;)
            else:
                n_iter_prev = n_iter
                n_iter += a[&#39;iter&#39;]
                mean_diff = mean_est - a[&#39;mean&#39;]
                mean_est *= n_iter_prev
                mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                mean_est /= n_iter
                var_est += a[&#39;sum_diff_sq&#39;]
                var_est += mean_diff**2 * (a[&#39;iter&#39;] * n_iter_prev) / n_iter
    if n_iter &lt; 2:
        raise AdaptationError(
            &#39;At least two chain samples required to compute a variance &#39;
            &#39;estimates.&#39;)
    var_est /= (n_iter - 1)
    self._regularize_var_est(var_est, n_iter)
    transition.system.metric = PositiveDiagonalMatrix(var_est).inv</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="mici.adapters.OnlineCovarianceMetricAdapter"><code class="flex name class">
<span>class <span class="ident">OnlineCovarianceMetricAdapter</span></span>
<span>(</span><span>reg_iter_offset=5, reg_scale=0.001)</span>
</code></dt>
<dd>
<section class="desc"><p>Dense metric adapter using online covariance estimates.</p>
<p>Uses Welford's algorithm [1] to stably compute an online estimate of the
sample covariane matrix of the chain state position components during
sampling. If online estimates are available from multiple independent
chains, the final covariance matrix estimate is calculated from the
per-chain statistics using a covariance variant due to Schubert and Gertz
[2] of the parallel / batched incremental variance algorithm described by
Chan et al. [3]. The covariance matrix estimates are optionally regularized
towards a scaled identity matrix, with increasing weight for small number of
samples, to decrease the effect of noisy estimates for small sample sizes,
following the approach in Stan [4]. The metric matrix representation is set
to a dense positive definite matrix corresponding to the inverse of the
(regularized) covariance matrix estimate.</p>
<h2 id="references">References</h2>
<ol>
<li>Welford, B. P., 1962. Note on a method for calculating corrected sums
of squares and products. Technometrics, 4(3), pp. 419–420.</li>
<li>Schubert, E. and Gertz, M., 2018. Numerically stable parallel
computation of (co-)variance. ACM. p. 10. doi:10.1145/3221269.3223036.</li>
<li>Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
a pairwise algorithm for computing sample variances. Technical Report
STAN-CS-79-773, Department of Computer Science, Stanford University.</li>
<li>Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
Stan: A probabilistic programming language. Journal of Statistical
Software, 76(1).</li>
</ol>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>reg_iter_offset</code></strong> :&ensp;<code>int</code></dt>
<dd>Iteration offset used for calculating
iteration dependent weighting between regularisation target and
current covariance estimate. Higher values cause stronger
regularisation during initial iterations.</dd>
<dt><strong><code>reg_scale</code></strong> :&ensp;<code>float</code></dt>
<dd>Positive scalar defining value variance estimates
are regularized towards.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L356-L459" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class OnlineCovarianceMetricAdapter(Adapter):
    &#34;&#34;&#34;Dense metric adapter using online covariance estimates.

    Uses Welford&#39;s algorithm [1] to stably compute an online estimate of the
    sample covariane matrix of the chain state position components during
    sampling. If online estimates are available from multiple independent
    chains, the final covariance matrix estimate is calculated from the
    per-chain statistics using a covariance variant due to Schubert and Gertz
    [2] of the parallel / batched incremental variance algorithm described by
    Chan et al. [3]. The covariance matrix estimates are optionally regularized
    towards a scaled identity matrix, with increasing weight for small number of
    samples, to decrease the effect of noisy estimates for small sample sizes,
    following the approach in Stan [4]. The metric matrix representation is set
    to a dense positive definite matrix corresponding to the inverse of the
    (regularized) covariance matrix estimate.


    References:

      1. Welford, B. P., 1962. Note on a method for calculating corrected sums
         of squares and products. Technometrics, 4(3), pp. 419–420.
      2. Schubert, E. and Gertz, M., 2018. Numerically stable parallel
         computation of (co-)variance. ACM. p. 10. doi:10.1145/3221269.3223036.
      3. Chan, T. F., Golub, G. H., LeVeque, R. J., 1979. Updating formulae and
         a pairwise algorithm for computing sample variances. Technical Report
         STAN-CS-79-773, Department of Computer Science, Stanford University.
      4. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B.,
         Betancourt, M., Brubaker, M., Guo, J., Li, P. and Riddell, A., 2017.
         Stan: A probabilistic programming language. Journal of Statistical
         Software, 76(1).
    &#34;&#34;&#34;

    def __init__(self, reg_iter_offset=5, reg_scale=1e-3):
        &#34;&#34;&#34;
        Args:
            reg_iter_offset (int): Iteration offset used for calculating
                iteration dependent weighting between regularisation target and
                current covariance estimate. Higher values cause stronger
                regularisation during initial iterations.
            reg_scale (float): Positive scalar defining value variance estimates
                are regularized towards.
        &#34;&#34;&#34;
        self.reg_iter_offset = reg_iter_offset
        self.reg_scale = reg_scale

    def initialize(self, chain_state, transition):
        dim_pos = chain_state.pos.shape[0]
        dtype = chain_state.pos.dtype
        return {
            &#39;iter&#39;: 0,
            &#39;mean&#39;: np.zeros(shape=(dim_pos,), dtype=dtype),
            &#39;sum_diff_outer&#39;: np.zeros(shape=(dim_pos, dim_pos), dtype=dtype)
        }

    def update(self, adapt_state, chain_state, trans_stats, transition):
        # Use Welford (1962) incremental algorithm to update statistics to
        # calculate online covariance estimate
        # https://en.wikipedia.org/wiki/
        #  Algorithms_for_calculating_variance#Online
        adapt_state[&#39;iter&#39;] += 1
        pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
        adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
        adapt_state[&#39;sum_diff_outer&#39;] += pos_minus_mean[None, :] * (
            chain_state.pos - adapt_state[&#39;mean&#39;])[:, None]

    def _regularize_covar_est(self, covar_est, n_iter):
        &#34;&#34;&#34;Update covariance estimate by regularising towards identity.

        Performed in place to prevent further array allocations.
        &#34;&#34;&#34;
        covar_est *= (n_iter / (self.reg_iter_offset + n_iter))
        covar_est_diagonal = np.einsum(&#39;ii-&gt;i&#39;, covar_est)
        covar_est_diagonal += self.reg_scale * (
            self.reg_iter_offset / (self.reg_iter_offset + n_iter))

    def finalize(self, adapt_state, transition):
        if isinstance(adapt_state, dict):
            n_iter = adapt_state[&#39;iter&#39;]
            covar_est = adapt_state.pop(&#39;sum_diff_outer&#39;)
        else:
            # Use Schubert and Gertz (2018) parallel covariance estimation
            # algorithm to combine per-chain statistics
            for i, a in enumerate(adapt_state):
                if i == 0:
                    n_iter = a[&#39;iter&#39;]
                    mean_est = a.pop(&#39;mean&#39;)
                    covar_est = a.pop(&#39;sum_diff_outer&#39;)
                else:
                    n_iter_prev = n_iter
                    n_iter += a[&#39;iter&#39;]
                    mean_diff = mean_est - a[&#39;mean&#39;]
                    mean_est *= n_iter_prev
                    mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                    mean_est /= n_iter
                    covar_est += a[&#39;sum_diff_outer&#39;]
                    covar_est += np.outer(mean_diff, mean_diff) * (
                        a[&#39;iter&#39;] * n_iter_prev) / n_iter
        if n_iter &lt; 2:
            raise AdaptationError(
                &#39;At least two chain samples required to compute a variance &#39;
                &#39;estimates.&#39;)
        covar_est /= (n_iter - 1)
        self._regularize_covar_est(covar_est, n_iter)
        transition.system.metric = DensePositiveDefiniteMatrix(covar_est).inv</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="mici.adapters.Adapter" href="#mici.adapters.Adapter">Adapter</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="mici.adapters.OnlineCovarianceMetricAdapter.initialize"><code class="name flex">
<span>def <span class="ident">initialize</span></span>(<span>self, chain_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize adapter state prior to starting adaptive transitions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Initial chain state adaptive
transition will be started from. May be used to calculate
initial adapter state but should not be mutated by method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Initial adapter state.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L401-L408" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def initialize(self, chain_state, transition):
    dim_pos = chain_state.pos.shape[0]
    dtype = chain_state.pos.dtype
    return {
        &#39;iter&#39;: 0,
        &#39;mean&#39;: np.zeros(shape=(dim_pos,), dtype=dtype),
        &#39;sum_diff_outer&#39;: np.zeros(shape=(dim_pos, dim_pos), dtype=dtype)
    }</code></pre>
</details>
</dd>
<dt id="mici.adapters.OnlineCovarianceMetricAdapter.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, adapt_state, chain_state, trans_stats, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update adapter state after sampling transition being adapted.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>]</dt>
<dd>Current adapter state. Entries will
be updated in-place by the method.</dd>
<dt><strong><code>chain_state</code></strong> :&ensp;<a title="mici.states.ChainState" href="states.html#mici.states.ChainState"><code>ChainState</code></a></dt>
<dd>Current chain state following
sampling from transition being adapted. May be used to calculate
adapter state updates but should not be mutated by method.</dd>
<dt><strong><code>trans_stats</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>numeric</code>]</dt>
<dd>Dictionary of statistics
associated with transition being adapted. May be used to
calculate adapter state updates but should not be mutated by
method.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects may be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L410-L419" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update(self, adapt_state, chain_state, trans_stats, transition):
    # Use Welford (1962) incremental algorithm to update statistics to
    # calculate online covariance estimate
    # https://en.wikipedia.org/wiki/
    #  Algorithms_for_calculating_variance#Online
    adapt_state[&#39;iter&#39;] += 1
    pos_minus_mean = chain_state.pos - adapt_state[&#39;mean&#39;]
    adapt_state[&#39;mean&#39;] += pos_minus_mean / adapt_state[&#39;iter&#39;]
    adapt_state[&#39;sum_diff_outer&#39;] += pos_minus_mean[None, :] * (
        chain_state.pos - adapt_state[&#39;mean&#39;])[:, None]</code></pre>
</details>
</dd>
<dt id="mici.adapters.OnlineCovarianceMetricAdapter.finalize"><code class="name flex">
<span>def <span class="ident">finalize</span></span>(<span>self, adapt_state, transition)</span>
</code></dt>
<dd>
<section class="desc"><p>Update transition parameters based on final adapter state or states.</p>
<p>Optionally, if multiple adapter states are available, e.g. from a set of
independent adaptive chains, then these adaptation information from all
the chains may be combined to set the transition parameter(s).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>adapt_state</code></strong> :&ensp;<code>Dict</code>[<code>str</code>, <code>Any</code>] or <code>List</code>[<code>Dict</code>[<code>str</code>, <code>Any</code>]]</dt>
<dd>Final adapter
state or a list of adapter states. Arrays / buffers associated
with the adapter state entries may be recycled to reduce memory
usage - if so the corresponding entries will be removed from
the adapter state dictionary / dictionaries.</dd>
<dt><strong><code>transition</code></strong> :&ensp;<a title="mici.transitions.Transition" href="transitions.html#mici.transitions.Transition"><code>Transition</code></a></dt>
<dd>Markov transition being
adapted. Attributes of the transition or child objects will be
updated in-place by the method.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/matt-graham/mici/blob/39019d0bfc441dc54a297e7623bac13534f7c2c1/mici/adapters.py#L431-L459" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def finalize(self, adapt_state, transition):
    if isinstance(adapt_state, dict):
        n_iter = adapt_state[&#39;iter&#39;]
        covar_est = adapt_state.pop(&#39;sum_diff_outer&#39;)
    else:
        # Use Schubert and Gertz (2018) parallel covariance estimation
        # algorithm to combine per-chain statistics
        for i, a in enumerate(adapt_state):
            if i == 0:
                n_iter = a[&#39;iter&#39;]
                mean_est = a.pop(&#39;mean&#39;)
                covar_est = a.pop(&#39;sum_diff_outer&#39;)
            else:
                n_iter_prev = n_iter
                n_iter += a[&#39;iter&#39;]
                mean_diff = mean_est - a[&#39;mean&#39;]
                mean_est *= n_iter_prev
                mean_est += a[&#39;iter&#39;] * a[&#39;mean&#39;]
                mean_est /= n_iter
                covar_est += a[&#39;sum_diff_outer&#39;]
                covar_est += np.outer(mean_diff, mean_diff) * (
                    a[&#39;iter&#39;] * n_iter_prev) / n_iter
    if n_iter &lt; 2:
        raise AdaptationError(
            &#39;At least two chain samples required to compute a variance &#39;
            &#39;estimates.&#39;)
    covar_est /= (n_iter - 1)
    self._regularize_covar_est(covar_est, n_iter)
    transition.system.metric = DensePositiveDefiniteMatrix(covar_est).inv</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
</main>
<footer id="footer">
Copyright © 2019 Matt Graham
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2.dev0+g1b644f6.d20200630</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad(); hljs.configure({languages: ["python"]});</script>
</body>
</html>